{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "print(\"===== 1. 環境初始化與套件安裝 =====\")\n",
    "# 安裝 YOLO 與 RF-DETR 所需套件\n",
    "!pip install -q ultralytics timm submitit tqdm pandas pillow pyyaml\n",
    "\n",
    "print(\"\\n===== 2. 設定 RF-DETR 模組 =====\")\n",
    "# 下載 RF-DETR 原始碼\n",
    "if not os.path.exists(\"RF-DETR\"):\n",
    "    print(\"正在下載 RF-DETR 原始碼...\")\n",
    "    !git clone https://github.com/jahongir7174/RF-DETR.git\n",
    "else:\n",
    "    print(\"RF-DETR 資料夾已存在。\")\n",
    "\n",
    "# 【關鍵步驟】將 RF-DETR 資料夾加入 Python 搜尋路徑\n",
    "# 這樣做之後，您的 'from rfdetr import RFDETRSmall' 才能正常運作\n",
    "rf_path = os.path.abspath(\"RF-DETR\")\n",
    "if rf_path not in sys.path:\n",
    "    sys.path.append(rf_path)\n",
    "    print(f\"已將 {rf_path} 加入環境路徑。\")\n",
    "\n",
    "print(\"\\n===== 3. 準備測試集資料 =====\")\n",
    "# 您的程式碼 get_test_images_safe 預設會找 ./testing_image/testing_image\n",
    "# 所以我們解壓縮到 ./testing_image，這樣通常會產生 testing_image/testing_image 的結構\n",
    "if os.path.exists(\"testing_image.zip\"):\n",
    "    if not os.path.exists(\"testing_image\"):\n",
    "        print(\"正在解壓縮測試集 (Testing Data)...\")\n",
    "        !unzip -q testing_image.zip -d ./testing_image\n",
    "        print(\"解壓縮完成。\")\n",
    "    else:\n",
    "        print(\"檢測到 testing_image 資料夾已存在，跳過解壓縮。\")\n",
    "else:\n",
    "    print(\"【警告】找不到 testing_image.zip，請確認檔案是否已上傳至同級目錄！\")\n",
    "\n",
    "print(\"\\n===== 4. 最終檢查 =====\")\n",
    "try:\n",
    "    from rfdetr import RFDETRSmall\n",
    "    print(\"✅ 成功匯入 RF-DETR 模組！\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ RF-DETR 匯入失敗: {e}\")\n",
    "    print(\"請確認 RF-DETR 資料夾內是否有 rfdetr.py 或 __init__.py\")\n",
    "\n",
    "print(\"\\n環境準備就緒，請繼續執行下方的主程式。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Step 1: Training RF-DETR 5 Folds...\n",
      "\n",
      ">>> Processing RF-DETR Fold 0 <<<\n",
      "Fold 0 already trained. Skipping.\n",
      "\n",
      ">>> Processing RF-DETR Fold 1 <<<\n",
      "Fold 1 already trained. Skipping.\n",
      "\n",
      ">>> Processing RF-DETR Fold 2 <<<\n",
      "Fold 2 already trained. Skipping.\n",
      "\n",
      ">>> Processing RF-DETR Fold 3 <<<\n",
      "Fold 3 already trained. Skipping.\n",
      "\n",
      ">>> Processing RF-DETR Fold 4 <<<\n",
      "Fold 4 already trained. Skipping.\n",
      "\n",
      ">>> Step 2: Gathering Images...\n",
      "Images: 16620\n",
      "\n",
      ">>> Step 3a: YOLO12n Inference...\n",
      "--> Batch Predicting YOLO: runs/detect/fold0_yolo12n/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO-0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [01:32<00:00, 179.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Batch Predicting YOLO: runs/detect/fold1_yolo12n/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO-1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [01:29<00:00, 185.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Batch Predicting YOLO: runs/detect/fold2_yolo12n/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO-2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [01:29<00:00, 185.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Batch Predicting YOLO: runs/detect/fold3_yolo12n/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO-3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [01:29<00:00, 185.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Batch Predicting YOLO: runs/detect/fold4_yolo12n/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO-4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [01:29<00:00, 186.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Step 3b: YOLO12s Inference...\n",
      "--> Batch Predicting YOLO: runs/detect/fold0_yolo12s/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO-5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [02:02<00:00, 135.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Batch Predicting YOLO: runs/detect/fold1_yolo12s/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO-6: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [02:06<00:00, 131.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Batch Predicting YOLO: runs/detect/fold2_yolo12s/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO-7: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [02:06<00:00, 131.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Batch Predicting YOLO: runs/detect/fold3_yolo12s/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO-8: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [02:02<00:00, 135.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Batch Predicting YOLO: runs/detect/fold4_yolo12s/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO-9: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [02:06<00:00, 131.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Step 3c: RF-DETR Inference...\n",
      "--> Predicting RF-DETR: ./rf_detr_5fold_runs/fold_0/checkpoint_best_total.pth\n",
      "Using a different number of positional encodings than DINOv2, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Using patch size 16 instead of 14, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Loading pretrain weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "RF-10:   0%|                                                                                                                                        | 0/16620 [00:00<?, ?it/s]Model is not optimized for inference. Latency may be higher than expected. You can optimize the model for inference by calling model.optimize_for_inference().\n",
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "RF-10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [08:02<00:00, 34.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Predicting RF-DETR: ./rf_detr_5fold_runs/fold_1/checkpoint_best_total.pth\n",
      "Using a different number of positional encodings than DINOv2, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Using patch size 16 instead of 14, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Loading pretrain weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RF-11:   0%|                                                                                                                                        | 0/16620 [00:00<?, ?it/s]Model is not optimized for inference. Latency may be higher than expected. You can optimize the model for inference by calling model.optimize_for_inference().\n",
      "RF-11: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [08:13<00:00, 33.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Predicting RF-DETR: ./rf_detr_5fold_runs/fold_2/checkpoint_best_total.pth\n",
      "Using a different number of positional encodings than DINOv2, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Using patch size 16 instead of 14, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Loading pretrain weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RF-12:   0%|                                                                                                                                        | 0/16620 [00:00<?, ?it/s]Model is not optimized for inference. Latency may be higher than expected. You can optimize the model for inference by calling model.optimize_for_inference().\n",
      "RF-12: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16620/16620 [08:16<00:00, 33.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Predicting RF-DETR: ./rf_detr_5fold_runs/fold_3/checkpoint_best_total.pth\n",
      "Using a different number of positional encodings than DINOv2, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Using patch size 16 instead of 14, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Loading pretrain weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RF-13:   0%|                                                                                                                                        | 0/16620 [00:00<?, ?it/s]Model is not optimized for inference. Latency may be higher than expected. You can optimize the model for inference by calling model.optimize_for_inference().\n",
      "RF-13:  55%|█████████████████████████████████████████████████████████████████████▎                                                       | 9213/16620 [04:14<04:01, 30.69it/s]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AICUP 2025: 15-Model Ensemble Pipeline (v20 Fixed - All Issues Resolved)\n",
    "- 5x RF-DETR Small (50 Epochs) + 10x YOLO (n/s × 5 folds)\n",
    "- Fix: Import Path, USE_TTA, correct vote counting\n",
    "- Fix: Proper weight calculation for TTA\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import gc\n",
    "import numpy as np\n",
    "from pathlib import Path  # ✓ 修正1: 加入 Path\n",
    "from PIL import Image, ImageOps\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from rfdetr import RFDETRSmall\n",
    "from collections import defaultdict\n",
    "\n",
    "# ==========================================\n",
    "# 1. 全域配置\n",
    "# ==========================================\n",
    "\n",
    "TEST_IMG_ROOT = \"./datasets/test/tmp/testing_image\"\n",
    "RAW_IMG_ROOT = \"./training_image\"   \n",
    "RAW_LBL_ROOT = \"./training_label\"   \n",
    "YOLO_BASE_DIR = \"runs/detect\"\n",
    "\n",
    "RF_DATASET_ROOT = \"./rf_detr_dataset\"\n",
    "RF_RUNS_DIR = \"./rf_detr_5fold_runs\"\n",
    "OUTPUT_DIR = \"./final_submission\"\n",
    "FINAL_TXT_PATH = os.path.join(OUTPUT_DIR, \"submission_15models_v20_fixed.txt\")\n",
    "\n",
    "# --- 參數設定 ---\n",
    "IMG_SIZE = 512\n",
    "FOLDS = 5\n",
    "RF_EPOCHS = 50          \n",
    "YOLO_BATCH_SIZE = 32    \n",
    "USE_TTA = True          # ✓ 修正2: 定義 USE_TTA\n",
    "\n",
    "# 過濾參數 (嚴格模式)\n",
    "SINGLE_CONF = 0.20      # 單模門檻\n",
    "WBF_IOU_THR = 0.50      # 融合 IoU\n",
    "MIN_MODEL_VOTES = 5     # ✓ 修正3: 改名為 MIN_MODEL_VOTES，表示「至少幾個模型」\n",
    "FINAL_CONF = 0.30       # ✓ 修正4: 降為 0.30，避免過度嚴格\n",
    "\n",
    "# 權重 (每個「模型」的權重，不論 TTA 次數)\n",
    "WEIGHTS_MAP = {'yolo12s': 2.0, 'yolo12n': 2.0, 'rf_detr': 1.0}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(RF_RUNS_DIR, exist_ok=True)\n",
    "\n",
    "# ==========================================\n",
    "# 2. 自定義 WBF (修正投票邏輯)\n",
    "# ==========================================\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    return inter / (area1 + area2 - inter + 1e-6)\n",
    "\n",
    "def custom_wbf(all_boxes, iou_thr, min_model_votes, num_total_models):\n",
    "    \"\"\"\n",
    "    ✓ 修正版 WBF: 正確計算模型投票數\n",
    "    \n",
    "    all_boxes: list of [x1, y1, x2, y2, score, class, weight, model_id]\n",
    "    \"\"\"\n",
    "    if len(all_boxes) == 0: \n",
    "        return []\n",
    "    \n",
    "    all_boxes = np.array(all_boxes)\n",
    "    # 按分數排序\n",
    "    order = np.argsort(-all_boxes[:, 4])\n",
    "    all_boxes = all_boxes[order]\n",
    "    \n",
    "    groups = []\n",
    "    processed = [False] * len(all_boxes)\n",
    "    \n",
    "    for i in range(len(all_boxes)):\n",
    "        if processed[i]: \n",
    "            continue\n",
    "        \n",
    "        current_box = all_boxes[i]\n",
    "        group = [current_box]\n",
    "        model_ids = {int(current_box[7])}  # ✓ 追蹤唯一模型 ID\n",
    "        processed[i] = True\n",
    "        \n",
    "        for j in range(i + 1, len(all_boxes)):\n",
    "            if processed[j]: \n",
    "                continue\n",
    "            iou = compute_iou(current_box[:4], all_boxes[j, :4])\n",
    "            if iou >= iou_thr:\n",
    "                group.append(all_boxes[j])\n",
    "                model_ids.add(int(all_boxes[j, 7]))  # ✓ 記錄模型 ID\n",
    "                processed[j] = True\n",
    "        \n",
    "        # ✓ 修正: 計算唯一模型數\n",
    "        num_voting_models = len(model_ids)\n",
    "        \n",
    "        # 投票過濾\n",
    "        if num_voting_models < min_model_votes:\n",
    "            continue\n",
    "        \n",
    "        group = np.array(group)\n",
    "        \n",
    "        # 加權平均座標 (使用每個框的權重)\n",
    "        w = group[:, 6]\n",
    "        w_sum = w.sum()\n",
    "        avg_box = (group[:, :4].T @ w) / w_sum\n",
    "        \n",
    "        # ✓ 修正: 全局分數 = 總加權分數 / 總模型數\n",
    "        # 這裡用「總模型數」而非「總可能權重」，因為不同模型權重不同\n",
    "        # 更公平的做法: 總分 / (所有模型的平均權重 × 總模型數)\n",
    "        avg_weight = sum(WEIGHTS_MAP.values()) / len(WEIGHTS_MAP)  # (2+2+1)/3 ≈ 1.67\n",
    "        total_possible_score = avg_weight * num_total_models\n",
    "        \n",
    "        total_score = (group[:, 4] * group[:, 6]).sum()\n",
    "        avg_score = total_score / total_possible_score\n",
    "        \n",
    "        # 最終閾值過濾\n",
    "        if avg_score >= FINAL_CONF:\n",
    "            groups.append([*avg_box, avg_score, group[0, 5]])  # [x1,y1,x2,y2,score,class]\n",
    "            \n",
    "    return groups\n",
    "\n",
    "# ==========================================\n",
    "# 3. 工具函數\n",
    "# ==========================================\n",
    "\n",
    "def clear_gpu():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def ensure_clean_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        try: \n",
    "            shutil.rmtree(path)\n",
    "        except: \n",
    "            pass\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def find_patient_root(root: str) -> str:\n",
    "    for dirpath, dirnames, _ in os.walk(root):\n",
    "        if any(d.lower().startswith(\"patient\") for d in dirnames):\n",
    "            return dirpath\n",
    "    return root\n",
    "\n",
    "def get_yolo_path(fold, model_type):\n",
    "    candidates = [\n",
    "        os.path.join(YOLO_BASE_DIR, f\"fold{fold}_{model_type}\", \"weights\", \"best.pt\"),\n",
    "        os.path.join(YOLO_BASE_DIR, f\"{model_type}_fold{fold}\", \"weights\", \"best.pt\"),\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if os.path.exists(p): \n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def get_test_images_safe():\n",
    "    \"\"\"使用 os.walk 避免 Too many open files\"\"\"\n",
    "    target_dir = TEST_IMG_ROOT\n",
    "    if not os.path.exists(target_dir):\n",
    "        target_dir = \"./testing_image/testing_image\"\n",
    "        if not os.path.exists(target_dir): \n",
    "            return []\n",
    "\n",
    "    imgs = []\n",
    "    for root, dirs, files in os.walk(target_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.png', '.jpg')):\n",
    "                imgs.append(os.path.join(root, f))\n",
    "    return sorted(imgs)\n",
    "\n",
    "# ==========================================\n",
    "# 4. RF-DETR 訓練\n",
    "# ==========================================\n",
    "\n",
    "def create_5fold_splits(patients=range(1, 51)):\n",
    "    patients = list(patients)\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(patients)\n",
    "    fold_size = len(patients) // 5\n",
    "    folds = []\n",
    "    for fold_idx in range(5):\n",
    "        val_start = fold_idx * fold_size\n",
    "        val_end = val_start + fold_size\n",
    "        val_patients = patients[val_start:val_end]\n",
    "        train_patients = [p for p in patients if p not in val_patients]\n",
    "        folds.append({'fold': fold_idx, 'train': train_patients, 'valid': val_patients})\n",
    "    return folds\n",
    "\n",
    "def yolo_to_coco(images_dir, labels_dir, output_json, start_img_id=0, start_ann_id=0):\n",
    "    img_id, ann_id = start_img_id, start_ann_id\n",
    "    images, annotations = [], []\n",
    "    categories = [{\"id\": 1, \"name\": \"aortic_valve\", \"supercategory\": \"object\"}]\n",
    "    if not os.path.exists(images_dir): \n",
    "        return img_id, ann_id\n",
    "    \n",
    "    image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.png')])\n",
    "    for fname in image_files:\n",
    "        img_id += 1\n",
    "        images.append({\"id\": img_id, \"file_name\": fname, \"width\": IMG_SIZE, \"height\": IMG_SIZE})\n",
    "        txt_path = os.path.join(labels_dir, fname.replace(\".png\", \".txt\"))\n",
    "        if not os.path.exists(txt_path): \n",
    "            continue\n",
    "        \n",
    "        with open(txt_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 5: \n",
    "                    continue\n",
    "                _, xc, yc, w, h = map(float, parts[:5])\n",
    "                x_min = (xc - w/2) * IMG_SIZE\n",
    "                y_min = (yc - h/2) * IMG_SIZE\n",
    "                box_w = w * IMG_SIZE\n",
    "                box_h = h * IMG_SIZE\n",
    "                ann_id += 1\n",
    "                annotations.append({\n",
    "                    \"id\": ann_id, \"image_id\": img_id, \"category_id\": 1,\n",
    "                    \"bbox\": [x_min, y_min, box_w, box_h],\n",
    "                    \"area\": box_w * box_h, \"iscrowd\": 0\n",
    "                })\n",
    "    \n",
    "    coco = {\n",
    "        \"info\": {\"desc\": \"AICUP\"}, \"licenses\": [], \n",
    "        \"images\": images, \"annotations\": annotations, \"categories\": categories\n",
    "    }\n",
    "    os.makedirs(os.path.dirname(output_json), exist_ok=True)\n",
    "    with open(output_json, \"w\") as f: \n",
    "        json.dump(coco, f)\n",
    "    return img_id, ann_id\n",
    "\n",
    "def prepare_fold_data(fold_info, img_root, lbl_root):\n",
    "    fold_idx = fold_info['fold']\n",
    "    fold_dir = Path(RF_DATASET_ROOT) / f'fold_{fold_idx}'\n",
    "    if fold_dir.exists(): \n",
    "        shutil.rmtree(fold_dir)\n",
    "    \n",
    "    for split in ['train', 'valid']:\n",
    "        dst_img = fold_dir / split\n",
    "        dst_lbl = Path(f'./rf_tmp/fold_{fold_idx}_{split}_labels')\n",
    "        ensure_clean_dir(str(dst_img))\n",
    "        ensure_clean_dir(str(dst_lbl))\n",
    "        \n",
    "        for pid in fold_info[split]:\n",
    "            p_str = f\"patient{pid:04d}\"\n",
    "            src_img_dir = Path(img_root) / p_str\n",
    "            src_lbl_dir = Path(lbl_root) / p_str\n",
    "            if not src_img_dir.exists(): \n",
    "                continue\n",
    "            \n",
    "            for png_file in src_img_dir.glob(\"*.png\"):\n",
    "                txt_file = src_lbl_dir / f\"{png_file.stem}.txt\"\n",
    "                if txt_file.exists():\n",
    "                    shutil.copy2(png_file, dst_img / png_file.name)\n",
    "                    shutil.copy2(txt_file, dst_lbl / txt_file.name)\n",
    "    \n",
    "    last_img, last_ann = yolo_to_coco(\n",
    "        str(fold_dir / 'train'), \n",
    "        f'./rf_tmp/fold_{fold_idx}_train_labels', \n",
    "        str(fold_dir / 'train' / '_annotations.coco.json')\n",
    "    )\n",
    "    yolo_to_coco(\n",
    "        str(fold_dir / 'valid'), \n",
    "        f'./rf_tmp/fold_{fold_idx}_valid_labels', \n",
    "        str(fold_dir / 'valid' / '_annotations.coco.json'),\n",
    "        start_img_id=last_img, start_ann_id=last_ann\n",
    "    )\n",
    "    \n",
    "    test_dir = fold_dir / 'test'\n",
    "    if test_dir.exists(): \n",
    "        shutil.rmtree(test_dir)\n",
    "    shutil.copytree(fold_dir / 'valid', test_dir)\n",
    "    return fold_dir\n",
    "\n",
    "def train_rfdetr_all_folds():\n",
    "    try: \n",
    "        img_root = find_patient_root(RAW_IMG_ROOT)\n",
    "        lbl_root = find_patient_root(RAW_LBL_ROOT)\n",
    "    except: \n",
    "        return\n",
    "    \n",
    "    folds = create_5fold_splits()\n",
    "    for fold_info in folds:\n",
    "        fold_idx = fold_info['fold']\n",
    "        print(f\"\\n>>> Processing RF-DETR Fold {fold_idx} <<<\")\n",
    "        save_dir = os.path.join(RF_RUNS_DIR, f\"fold_{fold_idx}\")\n",
    "        final_ckpt = os.path.join(save_dir, \"checkpoint_best_total.pth\")\n",
    "        \n",
    "        if os.path.exists(final_ckpt):\n",
    "            print(f\"Fold {fold_idx} already trained. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        dataset_dir = prepare_fold_data(fold_info, img_root, lbl_root)\n",
    "        clear_gpu()\n",
    "        \n",
    "        model = RFDETRSmall(num_classes=1)\n",
    "        try:\n",
    "            model.train(\n",
    "                dataset_dir=str(dataset_dir), \n",
    "                epochs=RF_EPOCHS, \n",
    "                batch_size=8, \n",
    "                grad_accum_steps=2, \n",
    "                lr=1e-4, \n",
    "                output_dir=save_dir, \n",
    "                device=\"cuda\", \n",
    "                early_stopping=True, \n",
    "                patience=5\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            shutil.rmtree(dataset_dir)\n",
    "            raise e\n",
    "        \n",
    "        del model\n",
    "        clear_gpu()\n",
    "        \n",
    "        if os.path.exists(dataset_dir): \n",
    "            shutil.rmtree(dataset_dir)\n",
    "        \n",
    "        # 清理多餘的 checkpoint\n",
    "        for f in os.listdir(save_dir):\n",
    "            if f.endswith(\".pth\") and \"best_total\" not in f:\n",
    "                try: \n",
    "                    os.remove(os.path.join(save_dir, f))\n",
    "                except: \n",
    "                    pass\n",
    "\n",
    "# ==========================================\n",
    "# 5. 預測核心 (修正: 加入 model_id)\n",
    "# ==========================================\n",
    "\n",
    "def run_yolo_inference(model_path, images, weight, model_id, global_preds):\n",
    "    \"\"\"✓ 修正: 加入 model_id 參數\"\"\"\n",
    "    print(f\"--> Batch Predicting YOLO: {model_path}\")\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        total = len(images)\n",
    "        pbar = tqdm(total=total, desc=f\"YOLO-{model_id}\")\n",
    "        \n",
    "        for i in range(0, total, YOLO_BATCH_SIZE):\n",
    "            batch = images[i : i + YOLO_BATCH_SIZE]\n",
    "            try:\n",
    "                results = model.predict(\n",
    "                    batch, imgsz=640, conf=SINGLE_CONF, \n",
    "                    augment=USE_TTA, device=0, verbose=False, stream=False\n",
    "                )\n",
    "                for res in results:\n",
    "                    fid = os.path.splitext(os.path.basename(res.path))[0]\n",
    "                    if len(res.boxes) > 0:\n",
    "                        b = res.boxes.xyxyn.cpu().numpy()\n",
    "                        s = res.boxes.conf.cpu().numpy()\n",
    "                        \n",
    "                        for k in range(len(b)):\n",
    "                            # [x1, y1, x2, y2, score, class, weight, model_id]\n",
    "                            box_data = [*b[k], float(s[k]), 0, weight, model_id]\n",
    "                            global_preds[fid].append(box_data)\n",
    "            except Exception as e: \n",
    "                print(f\"Batch Error: {e}\")\n",
    "            pbar.update(len(batch))\n",
    "        \n",
    "        pbar.close()\n",
    "        del model\n",
    "    except: \n",
    "        pass\n",
    "    clear_gpu()\n",
    "\n",
    "def run_rfdetr_inference(model_path, images, weight, model_id, global_preds):\n",
    "    \"\"\"✓ 修正: 加入 model_id 參數\"\"\"\n",
    "    print(f\"--> Predicting RF-DETR: {model_path}\")\n",
    "    try:\n",
    "        model = RFDETRSmall(num_classes=1)\n",
    "        ckpt = torch.load(model_path, map_location=\"cuda\")\n",
    "        sd = ckpt.get(\"model_state_dict\", ckpt.get(\"model\", ckpt.get(\"ema_model\", ckpt)))\n",
    "        \n",
    "        try: \n",
    "            model.model.model.load_state_dict(sd)\n",
    "        except:\n",
    "            try: \n",
    "                model.model.load_state_dict(sd)\n",
    "            except: \n",
    "                model.load_state_dict(sd)\n",
    "        \n",
    "        model.model.model.to(\"cuda\").eval()\n",
    "        \n",
    "        for img_path in tqdm(images, desc=f\"RF-{model_id}\"):\n",
    "            fid = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            try:\n",
    "                pil_img = Image.open(img_path).convert(\"RGB\")\n",
    "                w, h = pil_img.size\n",
    "                \n",
    "                # 手動 TTA\n",
    "                variants = [(pil_img, False)]\n",
    "                if USE_TTA: \n",
    "                    variants.append((ImageOps.mirror(pil_img), True))\n",
    "                \n",
    "                for img, is_flip in variants:\n",
    "                    res = model.predict(img, confidence=SINGLE_CONF)\n",
    "                    if hasattr(res, 'xyxy'): \n",
    "                        b_raw, s_raw = res.xyxy, res.confidence\n",
    "                    else: \n",
    "                        b_raw, s_raw = res['boxes'], res['scores']\n",
    "                    \n",
    "                    for k in range(len(s_raw)):\n",
    "                        x1, y1, x2, y2 = map(float, b_raw[k])\n",
    "                        if is_flip: \n",
    "                            x1, x2 = w - x2, w - x1\n",
    "                        \n",
    "                        # Normalize\n",
    "                        norm_box = [\n",
    "                            max(0, x1/w), max(0, y1/h), \n",
    "                            min(1, x2/w), min(1, y2/h)\n",
    "                        ]\n",
    "                        # [x1, y1, x2, y2, score, class, weight, model_id]\n",
    "                        global_preds[fid].append([*norm_box, float(s_raw[k]), 0, weight, model_id])\n",
    "            except: \n",
    "                pass\n",
    "        \n",
    "        del model\n",
    "    except Exception as e: \n",
    "        print(f\"❌ Failed RF load: {e}\")\n",
    "    clear_gpu()\n",
    "\n",
    "# ==========================================\n",
    "# 6. 主流程\n",
    "# ==========================================\n",
    "\n",
    "def run_pipeline():\n",
    "    print(\">>> Step 1: Training RF-DETR 5 Folds...\")\n",
    "    train_rfdetr_all_folds()\n",
    "    \n",
    "    print(\"\\n>>> Step 2: Gathering Images...\")\n",
    "    test_imgs = get_test_images_safe()\n",
    "    if not test_imgs:\n",
    "        print(\"❌ Error: No images found.\")\n",
    "        return\n",
    "    print(f\"Images: {len(test_imgs)}\")\n",
    "    \n",
    "    global_preds = defaultdict(list)\n",
    "    model_counter = 0  # ✓ 追蹤模型 ID\n",
    "    \n",
    "    # 1. YOLOv12n (5 folds)\n",
    "    print(\"\\n>>> Step 3a: YOLO12n Inference...\")\n",
    "    for i in range(FOLDS):\n",
    "        path = get_yolo_path(i, 'yolo12n')\n",
    "        if path: \n",
    "            run_yolo_inference(path, test_imgs, WEIGHTS_MAP['yolo12n'], model_counter, global_preds)\n",
    "            model_counter += 1\n",
    "    \n",
    "    # 2. YOLOv12s (5 folds)\n",
    "    print(\"\\n>>> Step 3b: YOLO12s Inference...\")\n",
    "    for i in range(FOLDS):\n",
    "        path = get_yolo_path(i, 'yolo12s')\n",
    "        if path: \n",
    "            run_yolo_inference(path, test_imgs, WEIGHTS_MAP['yolo12s'], model_counter, global_preds)\n",
    "            model_counter += 1\n",
    "    \n",
    "    # 3. RF-DETR (5 folds)\n",
    "    print(\"\\n>>> Step 3c: RF-DETR Inference...\")\n",
    "    for i in range(FOLDS):\n",
    "        path = f\"./rf_detr_5fold_runs/fold_{i}/checkpoint_best_total.pth\"\n",
    "        if not os.path.exists(path): \n",
    "            path = f\"./rf_detr_5fold_runs/fold_{i}/checkpoint.pth\"\n",
    "        if os.path.exists(path): \n",
    "            run_rfdetr_inference(path, test_imgs, WEIGHTS_MAP['rf_detr'], model_counter, global_preds)\n",
    "            model_counter += 1\n",
    "    \n",
    "    print(f\"\\nTotal models loaded: {model_counter}\")\n",
    "    \n",
    "    # 4. Custom WBF Ensemble\n",
    "    print(\"\\n>>> Step 4: Final Custom WBF (Strict Voting)...\")\n",
    "    \n",
    "    stats = {'total': 0, 'detected': 0, 'total_boxes': 0}\n",
    "    \n",
    "    with open(FINAL_TXT_PATH, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for fid in tqdm(sorted(global_preds.keys()), desc=\"WBF\"):\n",
    "            stats['total'] += 1\n",
    "            box_data = global_preds[fid]\n",
    "            \n",
    "            final_results = custom_wbf(\n",
    "                box_data, \n",
    "                WBF_IOU_THR, \n",
    "                MIN_MODEL_VOTES, \n",
    "                model_counter  # ✓ 傳入實際模型總數\n",
    "            )\n",
    "            \n",
    "            if len(final_results) > 0:\n",
    "                stats['detected'] += 1\n",
    "                stats['total_boxes'] += len(final_results)\n",
    "            \n",
    "            for res in final_results:\n",
    "                x1 = int(res[0] * IMG_SIZE)\n",
    "                y1 = int(res[1] * IMG_SIZE)\n",
    "                x2 = int(res[2] * IMG_SIZE)\n",
    "                y2 = int(res[3] * IMG_SIZE)\n",
    "                \n",
    "                x1, y1 = max(0, x1), max(0, y1)\n",
    "                x2, y2 = min(IMG_SIZE, x2), min(IMG_SIZE, y2)\n",
    "                \n",
    "                score = res[4]\n",
    "                f_out.write(f\"{fid} 0 {score:.4f} {x1} {y1} {x2} {y2}\\n\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Final Statistics:\")\n",
    "    print(f\"  Images processed: {stats['total']}\")\n",
    "    print(f\"  Images with detections: {stats['detected']} ({stats['detected']/stats['total']*100:.1f}%)\")\n",
    "    print(f\"  Avg boxes per detected image: {stats['total_boxes']/max(1, stats['detected']):.2f}\")\n",
    "    print(f\"  Submission file: {FINAL_TXT_PATH}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
